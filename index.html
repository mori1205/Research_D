<!DOCTYPE html>
<html lang="en-us">

<head>
  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <title>4</title>
  <link rel="shortcut icon" href="TemplateData/favicon.ico">
  <link rel="stylesheet" href="TemplateData/style.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/css/starter-sample.css" />
  <script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
  <script src="https://unpkg.com/obniz@3.22.0/obniz.js" crossorigin="anonymous"></script>
  <div id="webcam-container"></div>
  <div id="label-container"></div>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
  <script>

    // let model, webcam, labelContainer, maxPredictions;
    var motor01, motor02;
    var button;
    var pressed;
    var count = 0; //一定時間に目を開いた回数
    let average = 0; //目を開いた確率
    // var data = []; //openクラスの値を入れる
    var obniz = new Obniz("4797-3778");
    var isMoterMoving = false; //モーターを動かさない
    // var go_sec_Count = 0;

    // const bufferSize = 20; // バッファのサイズ
    // const ringBuffer = new Array(bufferSize).fill(0);  // 初期化
    // let currentIndex = 0; // 現在のインデックス
    // var go_sec = Math.floor(Math.random() * (21 - 11) + 10) * 1000; //秒数
    // var finishLabel = 0;

    obniz.onconnect = async function () {
      button = obniz.wired("Button", { signal: 0, gnd: 2 });
      motor01 = obniz.wired("DCMotor", { forward: 4, back: 6 });
      motor02 = obniz.wired("DCMotor", { forward: 8, back: 10 });
      motor01.power(100); // 25
      motor02.power(100);

      button.onchange = function (pressed) {
        if(pressed) {
          eyedetection();
        }
        
      };

      obniz.display.clear();
      obniz.display.print("patipatiDrop");
    };

    // More API functions here:o
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    // const URL_ = "https://teachablemachine.withgoogle.com/models/GMnymkaDG/";



    // window.onload = function () {
    //   init();
    // };

    // Load the image model and setup the webcam
    // async function init() {
    //   // console.log("init呼び出し"); 

    //   const modelURL = URL_ + "model.json";
    //   const metadataURL = URL_ + "metadata.json";

    //   // load the model and metadata
    //   // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
    //   // or files from your local hard drive
    //   // Note: the pose library adds "tmImage" object to your window (window.tmImage)
    //   model = await tmImage.load(modelURL, metadataURL);
    //   maxPredictions = model.getTotalClasses();

    //   // Convenience function to setup a webcam
    //   const flip = true; // whether to flip the webcam
    //   webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
    //   await webcam.setup(); // request access to the webcam
    //   await webcam.play();
    //   window.requestAnimationFrame(loop);

    //   // append elements to the DOM
    //   // document.getElementById("webcam-container").appendChild(webcam.canvas); //カメラを表示
    //   labelContainer = document.getElementById("label-container");
    //   for (let i = 0; i < maxPredictions; i++) { // and class labels
    //     labelContainer.appendChild(document.createElement("div"));
    //   }

    //   var timer = async function () {
    //     let open_sum = 0;

    //     for (let i = 0; i < bufferSize; i++) {
    //       open_sum = open_sum + ringBuffer[i];
    //     }

    //     average = open_sum / bufferSize; //平均
    //     console.log(average);
    //   }
    //   setInterval(timer, 100);
    // }

    // async function loop() {
    //   webcam.update(); // update the webcam frame
    //   await predict();
    //   window.requestAnimationFrame(loop);
    // }

    // run the webcam image through the image model
    // async function predict() {
    //   // predict can take in an image, video or canvas html element
    //   const prediction = await model.predict(webcam.canvas);

    //   prediction[0].className = "Close";
    //   prediction[1].className = "Open";
    //   // get the best prediction
    //   let max_id = 0;
    //   let max = -1;

    //   for (let i = 0; i < maxPredictions; i++) {
    //     if (prediction[i].probability > max) {
    //       max_id = i;
    //       max = prediction[i].probability;
    //     }
    //   }
    //   // ringBuffer[currentIndex] = prediction[1].probability;
    //   // console("prediciont " + prediction[1].probability);
    //   // console.log("addToRing");
    //   addToRingBuffer(prediction[1].probability);
    // }

    // function addToRingBuffer(opneValue) {
    //   ringBuffer[currentIndex] = opneValue;
    //   currentIndex = (currentIndex + 1) % bufferSize; // リングバッファの最大サイズを超えたら0に戻る
    // }



    function eyedetection() { //点眼する
      console.log("-----");
      if (isMoterMoving == false) {
        // console.log("tenngann");
        motor01.forward();
        motor02.forward();
        isMoterMoving = true;
        setTimeout(function () {
          motor01.stop();
          motor02.stop();
          webcam.stop();
          isMoterMoving = false;
        }, 1800);
      }
    }

  </script>
  </body>

</html>